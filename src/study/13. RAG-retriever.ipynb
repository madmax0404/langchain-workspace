{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21ed6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd499b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebbe895",
   "metadata": {},
   "source": [
    "##### 검색을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93850c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":열린_파일_폴더: Processing folder: JAVA_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 10_다형성.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 11_기본API.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 12_예외처리(Exception).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 13_입출력(IO).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 14-1_컬렉션(Collection).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 14-2_제네릭스(Generics).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 15_스레드.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 18_네트워크(Network).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_프로그래밍기초.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_변수(Variable).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 3_연산자(Operator).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 4_제어문.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 5_배열.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 6_2차원배열.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 7_객체.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 8_객체배열.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 9_상속.pdf\n",
      ":열린_파일_폴더: Processing folder: JDBC_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 1_JDBC개요.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_JDBC실습구조.pdf\n",
      ":열린_파일_폴더: Processing folder: JQ_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 0_개요.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_객체탐색.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_객체조작.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 3_이벤트.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 4_Effect.pdf\n",
      ":열린_파일_폴더: Processing folder: JS_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 0_개요.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_기본문법.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_배열.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 3_함수.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 4_객체.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 6_BOM.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 7_DOM.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 8_이벤트.pdf\n",
      ":열린_파일_폴더: Processing folder: Mybatis_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 1_Framework.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_MyBatis.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 3_동적SQL.pdf\n",
      ":열린_파일_폴더: Processing folder: ORACLE_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 0-1_데이터베이스개요.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 0-2_개발환경구축.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_DDL(ALTER, DROP).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_DDL(CREATE).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_DML(INSERT, UPDATE, DELETE).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_DML(SELECT).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_함수(Function).pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 3_GROUP BY_HAVING4.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 4_JOIN.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 5_SUBQUERY.pdf\n",
      ":열린_파일_폴더: Processing folder: Spring_PDF\n",
      ":글씨가_쓰여진_페이지: Loading: 0_Framework.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 1_Maven.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 2_Spring기초.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 3_Spring IoC, DI.pdf\n",
      ":글씨가_쓰여진_페이지: Loading: 4_Spring DI XML.pdf\n"
     ]
    }
   ],
   "source": [
    "# 1. 임베더\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# 2. 텍스트 스플리터\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name=\"cl100k_base\"\n",
    ")\n",
    "\n",
    "# 3. Documents들 준비\n",
    "# RAG_PDF 아래의 모든 pdf파일을 로드.\n",
    "documents = []\n",
    "base_dir = \"../RAG_PDF\"\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)  # RAG_PDF/JAVA_PDF\n",
    "    if os.path.isdir(folder_path):  # 폴더인지 확인\n",
    "        print(f\":열린_파일_폴더: Processing folder: {folder_name}\")\n",
    "        # 현재 폴더내 pdf파일들 탐색\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                print(f\":글씨가_쓰여진_페이지: Loading: {file_name}\")  # 체크\n",
    "                # PDF 파일 로드\n",
    "                loader = PyMuPDFLoader(file_path)\n",
    "                document = loader.load_and_split(text_splitter=text_splitter)\n",
    "                documents.extend(document)\n",
    "\n",
    "# 4. Chroma db에 문서들 저장\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=documents, embedding=embeddings, persist_directory=\"../chroma_rag_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ec45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_572\\97103156.py:6: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"JVM에 대해 알려줘\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='ab0d83e4-6e32-4cf4-908e-519b50a45d7c', metadata={'total_pages': 26, 'source': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'author': 'user1', 'format': 'PDF 1.4', 'creator': 'Hancom PDF 1.3.0.538', 'page': 4, 'file_path': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'keywords': '', 'trapped': '', 'creationDate': \"D:20210107085705+09'00'\", 'moddate': '2021-01-07T08:57:05+09:00', 'subject': '', 'producer': 'Hancom PDF 1.3.0.538', 'title': '', 'modDate': \"D:20210107085705+09'00'\", 'creationdate': '2021-01-07T08:57:05+09:00'}, page_content='▶JVM(Java Virtual Machine)\\n자바를실행하기위한가상기계로플랫폼에의존적\\nbyte code(class파일)를해석하고실행하는interpreter'),\n",
       " Document(id='5caaef52-7906-4ab1-b96d-e45507cac0cd', metadata={'author': 'user1', 'modDate': \"D:20210107085705+09'00'\", 'creationdate': '2021-01-07T08:57:05+09:00', 'page': 4, 'trapped': '', 'creationDate': \"D:20210107085705+09'00'\", 'source': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'total_pages': 26, 'creator': 'Hancom PDF 1.3.0.538', 'producer': 'Hancom PDF 1.3.0.538', 'title': '', 'format': 'PDF 1.4', 'keywords': '', 'moddate': '2021-01-07T08:57:05+09:00', 'subject': '', 'file_path': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf'}, page_content='▶JVM(Java Virtual Machine)\\n자바를실행하기위한가상기계로플랫폼에의존적\\nbyte code(class파일)를해석하고실행하는interpreter'),\n",
       " Document(id='bffebddb-3b13-4d54-912c-5d3ef7e16ddd', metadata={'modDate': \"D:20210107085705+09'00'\", 'trapped': '', 'file_path': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'total_pages': 26, 'creator': 'Hancom PDF 1.3.0.538', 'source': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'author': 'user1', 'subject': '', 'moddate': '2021-01-07T08:57:05+09:00', 'page': 11, 'format': 'PDF 1.4', 'creationdate': '2021-01-07T08:57:05+09:00', 'title': '', 'keywords': '', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20210107085705+09'00'\"}, page_content='▶자바설정\\n변수값: JDK가설치된폴더\\n(C:\\\\Program Files\\\\Java\\\\jdk1.8.0_151\\\\bin;)')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity 기반\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"JVM에 대해 알려줘\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c935842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='▶JVM(Java Virtual Machine)\n",
      "자바를실행하기위한가상기계로플랫폼에의존적\n",
      "byte code(class파일)를해석하고실행하는interpreter' metadata={'total_pages': 26, 'source': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'author': 'user1', 'format': 'PDF 1.4', 'creator': 'Hancom PDF 1.3.0.538', 'page': 4, 'file_path': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'keywords': '', 'trapped': '', 'creationDate': \"D:20210107085705+09'00'\", 'moddate': '2021-01-07T08:57:05+09:00', 'subject': '', 'producer': 'Hancom PDF 1.3.0.538', 'title': '', 'modDate': \"D:20210107085705+09'00'\", 'creationdate': '2021-01-07T08:57:05+09:00'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e3caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ab0d83e4-6e32-4cf4-908e-519b50a45d7c', metadata={'file_path': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'source': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'author': 'user1', 'creationDate': \"D:20210107085705+09'00'\", 'creationdate': '2021-01-07T08:57:05+09:00', 'total_pages': 26, 'trapped': '', 'producer': 'Hancom PDF 1.3.0.538', 'keywords': '', 'title': '', 'page': 4, 'creator': 'Hancom PDF 1.3.0.538', 'format': 'PDF 1.4', 'subject': '', 'moddate': '2021-01-07T08:57:05+09:00', 'modDate': \"D:20210107085705+09'00'\"}, page_content='▶JVM(Java Virtual Machine)\\n자바를실행하기위한가상기계로플랫폼에의존적\\nbyte code(class파일)를해석하고실행하는interpreter'),\n",
       " Document(id='2315ce2e-5e68-40f3-93e6-fcad2c62fd2a', metadata={'source': 'RAG_PDF\\\\JAVA_PDF\\\\7_객체.pdf', 'subject': '', 'creator': 'Hancom PDF 1.3.0.538', 'total_pages': 51, 'moddate': '2021-01-20T10:16:41+09:00', 'modDate': \"D:20210120101641+09'00'\", 'trapped': '', 'page': 29, 'producer': 'Hancom PDF 1.3.0.538', 'keywords': '', 'creationdate': '2021-01-20T10:16:41+09:00', 'author': 'user1', 'file_path': 'RAG_PDF\\\\JAVA_PDF\\\\7_객체.pdf', 'title': '', 'format': 'PDF 1.4', 'creationDate': \"D:20210120101641+09'00'\"}, page_content='▶필드(Field) – 초기화순서\\nü 인스턴스변수\\nü 클래스변수\\nJVM\\n기본값\\n명시적\\n초기값\\n클래스\\n초기화블록\\n초기값\\nJVM\\n기본값\\n명시적\\n초기값\\n인스턴스\\n초기화블록\\n초기값\\n생성자를\\n통한\\n초기값'),\n",
       " Document(id='5475dddc-4446-4610-9f54-3cf9ee632848', metadata={'title': '', 'source': '../RAG_PDF\\\\ORACLE_PDF\\\\0-1_데이터베이스개요.pdf', 'author': 'user1', 'modDate': \"D:20210217114415+09'00'\", 'trapped': '', 'subject': '', 'file_path': '../RAG_PDF\\\\ORACLE_PDF\\\\0-1_데이터베이스개요.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'creationDate': \"D:20210217114415+09'00'\", 'creator': 'Hancom PDF 1.3.0.538', 'creationdate': '2021-02-17T11:44:15+09:00', 'page': 0, 'producer': 'Hancom PDF 1.3.0.538', 'keywords': '', 'moddate': '2021-02-17T11:44:15+09:00'}, page_content='Oracle Database\\n개요'),\n",
       " Document(id='558a1e7a-a48b-4aea-8fef-6f316157acfb', metadata={'moddate': '2021-01-07T08:57:05+09:00', 'modDate': \"D:20210107085705+09'00'\", 'format': 'PDF 1.4', 'creationDate': \"D:20210107085705+09'00'\", 'creator': 'Hancom PDF 1.3.0.538', 'file_path': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'subject': '', 'trapped': '', 'page': 0, 'producer': 'Hancom PDF 1.3.0.538', 'source': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'keywords': '', 'author': 'user1', 'title': '', 'total_pages': 26, 'creationdate': '2021-01-07T08:57:05+09:00'}, page_content='프로그래밍\\n기초'),\n",
       " Document(id='1b9c3fed-1516-4fde-ae86-af8543f7a0c8', metadata={'keywords': '', 'trapped': '', 'format': 'PDF 1.4', 'author': 'user1', 'producer': 'Hancom PDF 1.3.0.538', 'modDate': \"D:20210107085705+09'00'\", 'moddate': '2021-01-07T08:57:05+09:00', 'title': '', 'creationDate': \"D:20210107085705+09'00'\", 'source': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'subject': '', 'total_pages': 26, 'page': 8, 'creationdate': '2021-01-07T08:57:05+09:00', 'file_path': '../RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'creator': 'Hancom PDF 1.3.0.538'}, page_content='▶자바설치\\n모두Default로놓고next, 다음버튼클릭\\n폴더변경시폴더위치기억할것.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mmr 기반\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\":5, \"fetch_k\":50}\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"JVM에 대해 알려줘\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2046f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='▶JVM(Java Virtual Machine)\n",
      "자바를실행하기위한가상기계로플랫폼에의존적\n",
      "byte code(class파일)를해석하고실행하는interpreter' metadata={'file_path': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'source': 'RAG_PDF\\\\JAVA_PDF\\\\1_프로그래밍기초.pdf', 'author': 'user1', 'creationDate': \"D:20210107085705+09'00'\", 'creationdate': '2021-01-07T08:57:05+09:00', 'total_pages': 26, 'trapped': '', 'producer': 'Hancom PDF 1.3.0.538', 'keywords': '', 'title': '', 'page': 4, 'creator': 'Hancom PDF 1.3.0.538', 'format': 'PDF 1.4', 'subject': '', 'moddate': '2021-01-07T08:57:05+09:00', 'modDate': \"D:20210107085705+09'00'\"}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75030853",
   "metadata": {},
   "source": [
    "##### 검색결과를 프롬프트에 추가하여 LLM에게 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2f16c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: JVM은 자바를 실행하기 위한 가상 기계로, 플랫폼에 의존적이며 byte code를 해석하고 실행하는 interpreter이다. 필드는 초기화 순서에 따라 인스턴스 변수, 클래스 변수, 클래스 초기화 블록 순으로 초기화되며, 인스턴스는 생성자를 통해 초기값을 설정할 수 있다. 또한 JVM은 기본값, 명시적 초기값, 클래스 초기화 블록을 통해 초기화될 수 있다. 자바를 설치할 때는 모두 Default로 설정하고, 폴더를 변경하면 해당 위치를 기억해야 한다. \n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Question : {question}\n",
    "\"\"\"\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = OpenAI()\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"context\": format_docs(docs),\n",
    "    \"question\": \"JVM에 대해 알려줘\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9611b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spring은 자바 기반의 오픈 소스 애플리케이션 프레임워크로서, 웹 애플리케이션 개발을 위한 다양한 기능을 제공합니다. 이를 통해 개발자는 복잡한 웹 애플리케이션을 빠르고 쉽게 구축할 수 있습니다. Spring은 다양한 모듈로 구성되어 있으며, 이를 조합하여 필요한 기능을 선택적으로 사용할 수 있습니다. 또한 Spring은 큰 규모의 애플리케이션 개발에도 유연하고 확장 가능한 구조를 제공합니다. 이를 통해 생산성을 향상시키고 유지보수를 용이하게 만듭니다. \n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"context\": format_docs(docs),\n",
    "    \"question\": \"Spring에 대해 알려줘\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db98269",
   "metadata": {},
   "source": [
    "##### 간단한 RAG 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f5f383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Doucment Load(Web)\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://organization-bht.gitbook.io/khmkm/llm/1-llm/\",\n",
    "    encoding=\"utf-8\",\n",
    "    header_template={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. Text Splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 3. Embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 4. Vector Store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents=docs, embedding=openai_embedding)\n",
    "\n",
    "# 5. retriever\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# 6. LLM 정의\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68e642",
   "metadata": {},
   "source": [
    "##### MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69453ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 검색된 문서 갯수 ========== 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='54708d40-4c64-4990-b733-f200002afd28', metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'language': 'en', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북'}, page_content='시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language Model)Large(엄청나게 많은 데이터를 학습한) Language(인간의 언어를 처리하는) Model(딥러닝모델)LLM(Large Language Model)은 대규모 언어 모델을 의미하며,  인터넷, 책, 논문, 뉴스, 블로그 등 방대한 양의 텍스트 데이터를 학습한 인공지능 모델입니다. 이러한 데이터들은 트랜스포머 아키텍쳐기반의 모델들에 학습되어 학습한 데이터의 문맥과 패턴을 이해할 수 있습니다. 이로 인해 LLM은 사람의 질문에도 이해를 하고 사람처럼 소통할 수 있는 능력을 갖추게 되었습니다. 사람이 사용하는 언어를 기계가 처리하는 기술을 NLP(Natural'),\n",
       " Document(id='535fd0dc-3b3b-428d-a5dd-c922c8dbca0d', metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en'}, page_content='시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language Model)Large(엄청나게 많은 데이터를 학습한) Language(인간의 언어를 처리하는) Model(딥러닝모델)LLM(Large Language Model)은 대규모 언어 모델을 의미하며,  인터넷, 책, 논문, 뉴스, 블로그 등 방대한 양의 텍스트 데이터를 학습한 인공지능 모델입니다. 이러한 데이터들은 트랜스포머 아키텍쳐기반의 모델들에 학습되어 학습한 데이터의 문맥과 패턴을 이해할 수 있습니다. 이로 인해 LLM은 사람의 질문에도 이해를 하고 사람처럼 소통할 수 있는 능력을 갖추게 되었습니다. 사람이 사용하는 언어를 기계가 처리하는 기술을 NLP(Natural'),\n",
       " Document(id='7d61c7c9-3182-4d3b-8984-1cad5b357d76', metadata={'language': 'en', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language Model)Large(엄청나게 많은 데이터를 학습한) Language(인간의 언어를 처리하는) Model(딥러닝모델)LLM(Large Language Model)은 대규모 언어 모델을 의미하며,  인터넷, 책, 논문, 뉴스, 블로그 등 방대한 양의 텍스트 데이터를 학습한 인공지능 모델입니다. 이러한 데이터들은 트랜스포머 아키텍쳐기반의 모델들에 학습되어 학습한 데이터의 문맥과 패턴을 이해할 수 있습니다. 이로 인해 LLM은 사람의 질문에도 이해를 하고 사람처럼 소통할 수 있는 능력을 갖추게 되었습니다. 사람이 사용하는 언어를 기계가 처리하는 기술을 NLP(Natural'),\n",
       " Document(id='5c45ba7f-f77e-48e1-a82b-4529875d68f9', metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en'}, page_content='주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language Model)Large(엄청나게 많은 데이터를 학습한) Language(인간의 언어를 처리하는) Model(딥러닝모델)LLM(Large Language Model)은 대규모 언어 모델을 의미하며,  인터넷, 책, 논문, 뉴스, 블로그 등 방대한 양의 텍스트 데이터를 학습한 인공지능 모델입니다. 이러한 데이터들은 트랜스포머 아키텍쳐기반의 모델들에 학습되어 학습한 데이터의 문맥과 패턴을 이해할 수 있습니다. 이로 인해 LLM은 사람의 질문에도 이해를 하고 사람처럼 소통할 수 있는 능력을 갖추게 되었습니다. 사람이 사용하는 언어를 기계가 처리하는 기술을 NLP(Natural Language Processing)라고 부르는데 LLM의 NLP기술은 챗봇, 텍스트 번역, 요약 등 원래는 사람이 처리해야 했던 다양한 분야에서 사람을 대체하거나 보조하는 기술로써 활용되고 있습니다.많은 국내 기업에서도 기존의'),\n",
       " Document(id='72949c9f-12cc-4211-9353-33384f00a567', metadata={'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='재평가자RAGPowered by GitBookOn this pageIntro1. LLM(Large Language Model)2. LLM 작동원리3. LLM의 특징1) NLP처리에 특화2) LLM은 잘하는 것과 못하는 것이 혼재3) 할루시네이션(Hallucination) - 환각4) LLM은 정적모델 5)  LLM의 크기와 성능의 관계6)  LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는'),\n",
       " Document(id='b1c189f3-2a11-460d-bf4b-7f958c5c62f3', metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en'}, page_content='재평가자RAGPowered by GitBookOn this pageIntro1. LLM(Large Language Model)2. LLM 작동원리3. LLM의 특징1) NLP처리에 특화2) LLM은 잘하는 것과 못하는 것이 혼재3) 할루시네이션(Hallucination) - 환각4) LLM은 정적모델 5)  LLM의 크기와 성능의 관계6)  LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는'),\n",
       " Document(id='e636cb3d-3f79-44e4-8a35-ea9551f56a89', metadata={'language': 'en', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='재평가자RAGPowered by GitBookOn this pageIntro1. LLM(Large Language Model)2. LLM 작동원리3. LLM의 특징1) NLP처리에 특화2) LLM은 잘하는 것과 못하는 것이 혼재3) 할루시네이션(Hallucination) - 환각4) LLM은 정적모델 5)  LLM의 크기와 성능의 관계6)  LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는'),\n",
       " Document(id='c8378938-eb60-42f6-b279-e439220a42a6', metadata={'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='5)  LLM의 크기와 성능의 관계6)  LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는 시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. MultiQueryRetriever\n",
    "# - 사용자의 질문을 다각도로 해석하여 여러개의 질문을 생성.\n",
    "# - 여러개의 질문으로 벡터 스토어에서 검색 후 검색 결과를 결합한 프롬프트를 생성.\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# 8. retrieval\n",
    "question = \"LLM?\"\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "print(\"======== 검색된 문서 갯수 ==========\", len(relevant_docs))\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87435d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language Model)Large(엄청나게 많은 데이터를 학습한) Language(인간의 언어를 처리하는) Model(딥러닝모델)LLM(Large Language Model)은 대규모 언어 모델을 의미하며,  인터넷, 책, 논문, 뉴스, 블로그 등 방대한 양의 텍스트 데이터를 학습한 인공지능 모델입니다. 이러한 데이터들은 트랜스포머 아키텍쳐기반의 모델들에 학습되어 학습한 데이터의 문맥과 패턴을 이해할 수 있습니다. 이로 인해 LLM은 사람의 질문에도 이해를 하고 사람처럼 소통할 수 있는 능력을 갖추게 되었습니다. 사람이 사용하는 언어를 기계가 처리하는 기술을 NLP(Natural\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653ca9c",
   "metadata": {},
   "source": [
    "##### 프롬프트 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "035c5ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# GPT 응답 ############\n",
      "LLM(Large Language Model)은 대규모 언어 모델을 의미하며, 인터넷, 책, 논문, 뉴스, 블로그 등 방대한 양의 텍스트 데이터를 학습한 인공지능 모델입니다. LLM은 트랜스포머 아키텍처 기반으로 작동하며, 학습한 데이터의 문맥과 패턴을 이해하여 사람의 질문에 답하고 사람처럼 소통할 수 있는 능력을 갖추고 있습니다. 이 기술은 자연어 처리(NLP) 분야에서 활용되며, 챗봇, 텍스트 번역, 요약 등 다양한 분야에서 사람을 대체하거나 보조하는 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# 10. 프롬프트 정의\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Question : {question}\n",
    "\"\"\"\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "# 11 검색내용을 prompt에 추가하여 보강\n",
    "response = chain.invoke({'context': (format_docs(relevant_docs)) , \"question\": question})\n",
    "print(\"############# GPT 응답 ############\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b783f",
   "metadata": {},
   "source": [
    "##### Contextual Compression Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51ff4ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM?\n"
     ]
    }
   ],
   "source": [
    "# 8. Contextual Compression Retriever\n",
    "# - 검색된 문서들 중 쿼리와 관련된 정보만 압축하는 검색기.\n",
    "# - 쿼리와 무관한 정보를 삭제해 줌으로써 응답 품질을 향상.\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":5, \"fetch_k\":20, \"lambda_mult\":0.25})\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6599de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d3885e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f695d4d2-ec66-4568-9318-96c6235b5489', metadata={'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='LLM은 잘하는 것과 못하는 것이 혼재LLM은 다양한 응답을 생성할 수 있지만 , 기본적으로 확률에 의거한 응답을 반환하기 때문에 잘못된 응답일 가능성이 존재합니다.혹은 소설, 시, 광고 문구 작성 등 단순 검색 기반이 아닌 창의적인 답변 생성이 가능합니다.단, 요청한 내용과 상관이 없는 잘못된 정보를 반환할 수도 있습니다.(Hallucination)LLM은 언어 패턴을 기반으로 응답하도록 설계되었기 때문에, 복잡한 수학계산이나 논리적 추론에서 오류를 범할 수 있습니다. 다양한 수학문제 해결을 위해서는 외부 계산 API 시스템과 연동하도록 설정해 줘야 합니다.출처 : https://www.linkedin.com/posts/kaicheng-yang-43477213b_have-been-thinking-about-what-tasks-llms-activity-7161062110209146880-pHDn3) 할루시네이션(Hallucination) - 환각Hallucination이란,'),\n",
       " Document(id='0ec7bce7-6e1a-4f0a-a77f-5cfd12bf1a47', metadata={'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북'}, page_content='LLM도입시에는 프라이버시 문제, 정보의 정확성문제, 윤리적 문제 , 경제적 문제 등 고려해야할  부분들이 상당합니다.  이번 커리큘럼에서는 총 4장의 대단원에 걸쳐 이러한 문제를 해결한 챗봇 서비스를 함께 만들어볼 예정입니다.2. LLM 작동원리LLM은 어떻게 사용자의 질문의 의미를 파악하고 그에 맞는 적절한 답변을 생성해 줄 수 있을까요? 그 이유는 LLM의 학습 방법에 있습니다.LLM은 \"딥러닝(Deep Learning)\" 기술 중 트랜스포머(Transformer)라는 신경망 구조를 기반으로 만들어 졌습니다.  트랜스포머는 Self-Attention Mechanism을 통해 문장 내 단어들 사이의 관계를 파악하고, 문맥적 의미를 계산합니다. 이러한 구조 덕분에 LLM은 대규모 텍스트 데이터를 학습하며 문법, 언어 패턴, 사실 기반 지식까지 \"통계적\"으로 학습할 수 있게 됩니다.출처 :'),\n",
       " Document(id='50422147-ec59-4a84-adc5-d222fc43be94', metadata={'language': 'en', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='LLM은 사람처럼 의미를 이해하고 사용하는 것이 아닌 학습된 데이터를 바탕으로 통계적으로 \"가장 그럴듯한 단어(또는 토큰)\"를 다음에 예측하는 방식으로 작동합니다.3. LLM의 특징1) NLP처리에 특화LLM들은 인터넷의 방대한 텍스트 데이터를 학습하여 언어의 문맥과 패턴을 이해(통계적 예측을 통해)할 수 있습니다. LLM은 언어의 문맥과 패턴을 이해할 수 있으므로 자연어 처리(NLP)에 자주 활용되며, 이 분야로는 문서번역, 요약, 코드 생성, 챗봇 기능등이 있습니다. 당근이 LLM을 활용하는 방법 - https://oneoneone.kr/content/e9320560출처 : https://oneoneone.kr/content/e93205602) LLM은 잘하는 것과 못하는 것이 혼재LLM은 다양한 응답을 생성할 수 있지만 , 기본적으로 확률에 의거한 응답을 반환하기 때문에 잘못된 응답일 가능성이 존재합니다.혹은 소설, 시, 광고 문구 작성 등 단순 검색 기반이 아닌 창의적인'),\n",
       " Document(id='c8378938-eb60-42f6-b279-e439220a42a6', metadata={'language': 'en', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='5)  LLM의 크기와 성능의 관계6)  LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는 시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language'),\n",
       " Document(id='4ecb8d6b-f8f2-44cb-95e3-a4d683b6ae51', metadata={'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북'}, page_content='1장 LLM에 대한 이해 | 경민민 IT 핸드북🐯경민민 IT 핸드북CtrlKOrientation전달사항복습방법수료한 선배의 한마디간단 자기소개스터디백엔드Java1장 프로그래밍 기초2장 자바 메모리구조1. Stack2. Heap6장 객체8장 상속9장 다형성10장 추상클래스와 인터페이스13장 Generic14장 Thread15장 Network16장 Lamda1. 내부 클래스 (Inner Class)DTO , VO, Builder Pattern2. 람다 표현식 (Lambda Expression)3. 스트림 API (Stream API)Optional17장 EnumSQLSQLD데이터 모델링의 이해 - 스키마데이터 모델링의 이해 - ERD데이터 모델링의 이해 - 정규화데이터 모델링의 이해 - NULLOracle1장 개요2장 SQL3장 DQL/DML4장 DDL5장 DCL/TCL6장 Object7장 PL/SQL8장 쿼리  실행 계획JDBCStatementJDBC')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95140e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 10. 검색결과 압축\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "print(len(compressed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dec6259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en'}, page_content='LLM은 잘하는 것과 못하는 것이 혼재LLM은 다양한 응답을 생성할 수 있지만 , 기본적으로 확률에 의거한 응답을 반환하기 때문에 잘못된 응답일 가능성이 존재합니다.혹은 소설, 시, 광고 문구 작성 등 단순 검색 기반이 아닌 창의적인 답변 생성이 가능합니다.단, 요청한 내용과 상관이 없는 잘못된 정보를 반환할 수도 있습니다.(Hallucination)LLM은 언어 패턴을 기반으로 응답하도록 설계되었기 때문에, 복잡한 수학계산이나 논리적 추론에서 오류를 범할 수 있습니다. 다양한 수학문제 해결을 위해서는 외부 계산 API 시스템과 연동하도록 설정해 줘야 합니다.'),\n",
       " Document(metadata={'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'language': 'en'}, page_content='LLM은 \"딥러닝(Deep Learning)\" 기술 중 트랜스포머(Transformer)라는 신경망 구조를 기반으로 만들어 졌습니다.  트랜스포머는 Self-Attention Mechanism을 통해 문장 내 단어들 사이의 관계를 파악하고, 문맥적 의미를 계산합니다. 이러한 구조 덕분에 LLM은 대규모 텍스트 데이터를 학습하며 문법, 언어 패턴, 사실 기반 지식까지 \"통계적\"으로 학습할 수 있게 됩니다.'),\n",
       " Document(metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'language': 'en', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북'}, page_content='LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는 시스템을 탄생시켰습니다. 이 가운데 LLM(Large Language Model)은 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 가장 혁신적인 도구로 주목받고 있습니다이 장에서는 LLM의 개념, 작동 원리, 주요 특징, 그리고 활용 가능성을 살펴보겠습니다.1. LLM(Large Language'),\n",
       " Document(metadata={'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en'}, page_content='Language Processing)라고 부르는데 LLM의 NLP기술은 챗봇, 텍스트 번역, 요약 등 원래는 사람이 처리해야 했던 다양한 분야에서 사람을 대체하거나 보조하는 기술로써 활용되고 있습니다. 많은 국내 기업에서도 기존의 서비스에 AI기능을 추가한 AI서비스들을 여럿 보셨을 건데 이러한 서비스들의 base가 되는 기술이 LLM입니다. 이러한 LLM은 국내에서 자체적으로 개발하는 경우도 있고, 이미 생성된 LLM을 이용하는 경우도 있고 다양하지만, 현대의 시대적 흐름에서 LLM도입은 회사입장에서 선택이 아닌 필수가 되어가고 있습니다.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35fbcdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# GPT 응답 ############\n",
      "LLM은 \"Large Language Model\"의 약자로, 대규모 텍스트 데이터를 기반으로 언어를 이해하고 생성할 수 있는 인공지능 시스템입니다. LLM은 트랜스포머라는 신경망 구조를 기반으로 하며, Self-Attention Mechanism을 통해 문장 내 단어들 사이의 관계를 파악하고 문맥적 의미를 계산합니다. 이 모델은 다양한 응답을 생성할 수 있지만, 확률에 의거한 응답을 반환하기 때문에 잘못된 정보나 오류가 발생할 가능성이 있습니다. LLM은 챗봇, 텍스트 번역, 요약 등 다양한 자연어 처리(NLP) 작업에 활용되며, 현대의 기업에서 AI 기능을 추가하는 데 필수적인 기술로 자리잡고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'context': (format_docs(compressed_docs)) , \"question\": question})\n",
    "print(\"############# GPT 응답 ############\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea5333",
   "metadata": {},
   "source": [
    "##### Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce47dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\LangchainWorkspace\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\LangchainWorkspace\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user1\\.cache\\huggingface\\hub\\models--BAAI--bge-reranker-v2-m3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Reranker\n",
    "# - RAG의 마지막 단계에서 수행되며, 검색결과 내용을 다시 평가하여 좀 더 정확한 응답을 반환받기 위해 사용\n",
    "\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "# Reranker모델 초기화\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77d6fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\"llm\")\n",
    "print(len(compressed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4251154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# GPT 응답 ############\n",
      "LLM은 \"Large Language Model\"의 약자로, 자연어 처리(NLP) 기술을 기반으로 하여 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는 인공지능 모델입니다. LLM은 딥러닝 기술 중 트랜스포머라는 신경망 구조를 사용하여 문장 내 단어들 사이의 관계를 파악하고 문맥적 의미를 계산합니다. 이를 통해 대규모 텍스트 데이터를 학습하며 문법, 언어 패턴, 사실 기반 지식을 통계적으로 학습할 수 있습니다. LLM은 다양한 특징을 가지고 있으며, 사용 시 프라이버시, 정보의 정확성, 윤리적 문제, 경제적 문제 등을 고려해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'context': (format_docs(compressed_docs)) , \"question\": question})\n",
    "print(\"############# GPT 응답 ############\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a4ad5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b1c189f3-2a11-460d-bf4b-7f958c5c62f3', metadata={'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북'}, page_content='재평가자RAGPowered by GitBookOn this pageIntro1. LLM(Large Language Model)2. LLM 작동원리3. LLM의 특징1) NLP처리에 특화2) LLM은 잘하는 것과 못하는 것이 혼재3) 할루시네이션(Hallucination) - 환각4) LLM은 정적모델 5)  LLM의 크기와 성능의 관계6)  LLM은 편향적4. 대표 LLM 서비스1. GPT-42.  GPT-3.53. Claude 3 Opus4. Google DeepMind5. Amazon Olympus6. Meta LLMA27. X Grok CopyLLM 서비스1장 LLM에 대한 이해출처: https://www.darkreading.com/vulnerabilities-threats/top-lessons-cisos-owasp-llm-top-10Intro최근 인공지능(AI)의 발달은 자연어 처리(NLP) 기술을 통해 사람과 자연스럽게 대화하거나 복잡한 언어 작업을 수행할 수 있는'),\n",
       " Document(id='0ec7bce7-6e1a-4f0a-a77f-5cfd12bf1a47', metadata={'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'language': 'en', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/'}, page_content='LLM도입시에는 프라이버시 문제, 정보의 정확성문제, 윤리적 문제 , 경제적 문제 등 고려해야할  부분들이 상당합니다.  이번 커리큘럼에서는 총 4장의 대단원에 걸쳐 이러한 문제를 해결한 챗봇 서비스를 함께 만들어볼 예정입니다.2. LLM 작동원리LLM은 어떻게 사용자의 질문의 의미를 파악하고 그에 맞는 적절한 답변을 생성해 줄 수 있을까요? 그 이유는 LLM의 학습 방법에 있습니다.LLM은 \"딥러닝(Deep Learning)\" 기술 중 트랜스포머(Transformer)라는 신경망 구조를 기반으로 만들어 졌습니다.  트랜스포머는 Self-Attention Mechanism을 통해 문장 내 단어들 사이의 관계를 파악하고, 문맥적 의미를 계산합니다. 이러한 구조 덕분에 LLM은 대규모 텍스트 데이터를 학습하며 문법, 언어 패턴, 사실 기반 지식까지 \"통계적\"으로 학습할 수 있게 됩니다.출처 :'),\n",
       " Document(id='5c42d84e-e542-4dde-ade5-11497ae18908', metadata={'title': '1장 LLM에 대한 이해 | 경민민 IT 핸드북', 'source': 'https://organization-bht.gitbook.io/khmkm/llm/1-llm/', 'language': 'en'}, page_content='1장 LLM에 대한 이해 | 경민민 IT 핸드북🐯경민민 IT 핸드북CtrlKOrientation전달사항복습방법수료한 선배의 한마디간단 자기소개스터디백엔드Java1장 프로그래밍 기초2장 자바 메모리구조1. Stack2. Heap6장 객체8장 상속9장 다형성10장 추상클래스와 인터페이스13장 Generic14장 Thread15장 Network16장 Lamda1. 내부 클래스 (Inner Class)DTO , VO, Builder Pattern2. 람다 표현식 (Lambda Expression)3. 스트림 API (Stream API)Optional17장 EnumSQLSQLD데이터 모델링의 이해 - 스키마데이터 모델링의 이해 - ERD데이터 모델링의 이해 - 정규화데이터 모델링의 이해 - NULLOracle1장 개요2장 SQL3장 DQL/DML4장 DDL5장 DCL/TCL6장 Object7장 PL/SQL8장 쿼리  실행 계획JDBCStatementJDBC')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
